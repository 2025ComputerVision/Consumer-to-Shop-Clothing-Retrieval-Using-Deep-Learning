# Consumer-to-Shop-Clothing-Retrieval-Using-Deep-Learning
This is a repository of Consumer-to-Shop Clothing Retrieval Using Deep Learning project in 2025-2, Computer Vision, Ewha Womans University. 

This project addresses the Consumer-to-Shop (C2S) fashion image retrieval problem by formulating it as a metric learningâ€“based retrieval task. Using a sampled subset of the DeepFashion C2S dataset, we construct an embedding-based retrieval pipeline and analyze the impact of backbone selection, loss functions, and preprocessing strategies. EfficientNet-B3 with Batch-Hard Triplet Loss achieves the best overall performance among the tested configurations. We further demonstrate that careful preprocessing design, particularly bounding box margin adjustment and embedding dimension selection, improves retrieval performance without modifying the model architecture. The final model achieves Recall@1, Recall@5, and Recall@10 of 0.604, 0.694, and 0.727 on the test set, highlighting the importance of preprocessing and embedding design in consumer-to-shop fashion retrieval.

